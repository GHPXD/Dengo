"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
DENGO API - MAIN APPLICATION (PRODUCTION)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FastAPI application factory com todos os middlewares, configuraÃ§Ãµes e services.

Features:
    - Redis Cache (Smart Caching)
    - Machine Learning Model (Gradient Boosting)
    - OpenWeather API Integration
    - Health Check com status de serviÃ§os
"""

from contextlib import asynccontextmanager

from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.gzip import GZipMiddleware
from fastapi.responses import JSONResponse
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.errors import RateLimitExceeded
from slowapi.util import get_remote_address

from app.api import cities_router, dashboard_router
from app.api.state_statistics import router as state_statistics_router
from app.api.v1.endpoints.predictions import router as predictions_router
from app.api.heatmap import router as heatmap_router
from app.core.config import settings
from app.core.logger import logger
from app.services import cache_service
from app.services.prediction_service import prediction_service


@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    Gerencia ciclo de vida da aplicaÃ§Ã£o (startup/shutdown).
    
    Startup:
        - Conecta no Redis (cache)
        - Carrega modelo ML do disco
    
    Shutdown:
        - Fecha conexÃ£o com Redis
    """
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # STARTUP
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    logger.info("ğŸš€ Starting Dengo API...")
    logger.info(f"Environment: {settings.environment}")
    logger.info(f"Debug Mode: {settings.debug}")
    logger.info(f"API Version: {settings.api_version}")

    # Conecta ao Redis
    await cache_service.connect()

    # Carrega modelo de Machine Learning
    logger.info("ğŸ¤– Carregando modelo de Machine Learning...")
    ml_loaded = prediction_service.load_model()
    if ml_loaded:
        logger.success("âœ“ Modelo ML carregado com sucesso!")
    else:
        logger.warning("âš ï¸  Modelo ML nÃ£o carregado - usando fallback (regras baseadas em temperatura)")

    logger.success("âœ“ API Ready!")
    logger.info("â”€" * 80)

    yield

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # SHUTDOWN
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    logger.info("ğŸ›‘ Shutting down Dengo API...")

    # Fecha conexÃ£o com Redis
    await cache_service.disconnect()

    logger.info("âœ“ Shutdown complete")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RATE LIMITING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

limiter = Limiter(key_func=get_remote_address)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FASTAPI APP INSTANCE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

app = FastAPI(
    title=settings.api_title,
    version=settings.api_version,
    description=(
        "API para previsÃ£o de casos de dengue usando Machine Learning.\n\n"
        "**Features:**\n"
        "- PrediÃ§Ã£o de casos com base em clima e histÃ³rico\n"
        "- Cache inteligente (Redis) para economia de API calls\n"
        "- Dados do InfoDengue (FIOCRUZ) + OpenWeatherMap\n"
        "- Otimizado para Google Cloud Run (Free Tier)\n"
        "- Rate Limiting: 20 requests/minuto por IP"
    ),
    docs_url="/docs",
    redoc_url="/redoc",
    openapi_url="/openapi.json",
    lifespan=lifespan,
)

# Configurar encoding UTF-8 para todas as respostas JSON
from fastapi.responses import JSONResponse
from fastapi import Request
from starlette.middleware.base import BaseHTTPMiddleware

class UTF8JSONMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next):
        response = await call_next(request)
        if response.headers.get("content-type", "").startswith("application/json"):
            response.headers["content-type"] = "application/json; charset=utf-8"
        return response

app.add_middleware(UTF8JSONMiddleware)

# Adiciona Limiter ao app state
app.state.limiter = limiter

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MIDDLEWARES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# CORS (Permite requisiÃ§Ãµes do Flutter)
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.cors_origins,
    allow_credentials=settings.cors_allow_credentials,
    allow_methods=settings.cors_allow_methods,
    allow_headers=settings.cors_allow_headers,
)

# GZIP Compression (Reduz tamanho das respostas)
app.add_middleware(GZipMiddleware, minimum_size=1000)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ROUTERS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

app.include_router(
    dashboard_router, prefix=f"{settings.api_prefix}/dashboard", tags=["Dashboard"]
)

app.include_router(
    cities_router, prefix=f"{settings.api_prefix}/cities", tags=["Cities"]
)

app.include_router(
    predictions_router, prefix=settings.api_prefix, tags=["PrediÃ§Ãµes IA"]
)

app.include_router(
    state_statistics_router, prefix=settings.api_prefix, tags=["EstatÃ­sticas"]
)

app.include_router(
    heatmap_router, prefix=f"{settings.api_prefix}/heatmap", tags=["Heatmap"]
)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EXCEPTION HANDLERS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Rate Limit Exceeded Handler
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)


@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    """Handler global para exceÃ§Ãµes nÃ£o tratadas."""
    logger.error(f"Unhandled exception: {exc}")
    return JSONResponse(
        status_code=500,
        content={
            "error": "Internal Server Error",
            "message": str(exc) if settings.debug else "An error occurred",
        },
    )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# HEALTH CHECK (Para Google Cloud Run)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


@app.get("/health", tags=["Health"])
async def health_check():
    """
    Endpoint de health check usado pelo Google Cloud Run.
    
    Verifica status de:
        - API (sempre healthy se responder)
        - Redis (ping)
        - ML Model (loaded ou fallback)
    
    Returns:
        200 OK: Todos os serviÃ§os funcionando
        503 Service Unavailable: Algum serviÃ§o crÃ­tico offline
    """
    # Status da API
    health_status = {
        "status": "healthy",
        "environment": settings.environment,
        "version": settings.api_version,
        "services": {},
    }

    # Verifica Redis
    redis_status = "offline"
    if cache_service.is_connected:
        try:
            # Tenta ping
            if cache_service.redis_client:
                await cache_service.redis_client.ping()
                redis_status = "healthy"
        except Exception:
            redis_status = "error"
    
    health_status["services"]["redis"] = redis_status

    # Verifica Modelo ML
    ml_loaded = prediction_service.is_loaded
    # Nota: ML estÃ¡ desabilitado por baixa acurÃ¡cia (RÂ² < 0)
    # Usando fallback inteligente baseado em histÃ³rico + clima
    health_status["services"]["ml_model"] = {
        "status": "loaded" if ml_loaded else "not_loaded",
        "active": False,  # ML desabilitado temporariamente
        "using": "Fallback inteligente (histÃ³rico + clima)",
        "reason": "Modelo Keras com RÂ² negativo - fallback Ã© mais preciso",
        "model_path": str(prediction_service.model_path) if ml_loaded else None,
    }

    # Define status geral
    # Redis offline nÃ£o Ã© crÃ­tico (graceful degradation)
    # ML usando fallback nÃ£o Ã© erro, Ã© decisÃ£o consciente
    if redis_status == "error":
        health_status["status"] = "degraded"
    
    return health_status


@app.get("/", tags=["Root"])
async def root():
    """Endpoint raiz."""
    return {
        "message": "Dengo API",
        "version": settings.api_version,
        "docs": "/docs",
        "health": "/health",
    }
